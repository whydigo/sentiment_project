from flask import Flask, render_template, request, jsonify, send_file, session
from sentiment_model import BertSentimentAnalyzer
from topic_model import BertTopicClassifier, SimpleTopicClassifier
from excel_processor import ExcelProcessor, BatchAnalyzer
import time
import torch
import os
import uuid
import pandas as pd
from werkzeug.utils import secure_filename

app = Flask(__name__)
app.secret_key = 'your-secret-key-here-2024'  # –î–ª—è —Å–µ—Å—Å–∏–π
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB –º–∞–∫—Å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['DOWNLOAD_FOLDER'] = 'downloads'

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['DOWNLOAD_FOLDER'], exist_ok=True)

print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ BERT –º–æ–¥–µ–ª–µ–π...")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
sentiment_analyzer = BertSentimentAnalyzer()

# –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–º–∞—Ç–∏–∫–∏
try:
    topic_classifier = BertTopicClassifier()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å
    test_result = topic_classifier.classify("—Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
    if test_result['topic'] == 'other' and test_result['confidence'] < 0.6:
        print("‚ö†Ô∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –ø—Ä–æ—Å—Ç—É—é...")
        topic_classifier = SimpleTopicClassifier()
    else:
        print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è BERT –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–º–∞—Ç–∏–∫–∏")
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ BERT –º–æ–¥–µ–ª–∏: {e}")
    print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞—Ö")
    topic_classifier = SimpleTopicClassifier()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ Excel –∏ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∑–∞–¥–∞–Ω–∏–π
excel_processor = ExcelProcessor(sentiment_analyzer, topic_classifier)
batch_analyzer = BatchAnalyzer(excel_processor)

print("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –æ–¥–∏–Ω–æ—á–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    topics = topic_classifier.get_all_topics()
    return render_template('index.html', topics=topics, model_type=type(topic_classifier).__name__)

@app.route('/upload')
def upload_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel"""
    return render_template('upload.html')

@app.route('/analyze', methods=['POST'])
def analyze_text():
    """API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ (–æ–¥–∏–Ω–æ—á–Ω—ã–π —Ä–µ–∂–∏–º)"""
    data = request.get_json()
    
    if not data or 'text' not in data:
        return jsonify({'error': '–ù–µ —É–∫–∞–∑–∞–Ω —Ç–µ–∫—Å—Ç'}), 400
    
    text = data['text'].strip()
    
    if not text:
        return jsonify({'error': '–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç'}), 400
    
    start_time = time.time()
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ BERT
    sentiment_result = sentiment_analyzer.analyze(text)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–º–∞—Ç–∏–∫–∏
    topic_result = topic_classifier.classify(text)
    
    process_time = time.time() - start_time
    
    # –≠–º–æ–¥–∑–∏ –¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    emoji_map = {
        'positive': 'üòä',
        'negative': 'üò†', 
        'neutral': 'üòê'
    }
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    response = {
        'text': text,
        'sentiment': {
            'label': sentiment_result['sentiment'],
            'confidence': round(sentiment_result['confidence'], 4),
            'emoji': emoji_map.get(sentiment_result['sentiment'], 'ü§î'),
            'model': 'ruBERT (—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)',
            'probabilities': sentiment_result.get('probabilities', {})
        },
        'topic': {
            'label': topic_result['topic'],
            'name': topic_result['topic_name'],
            'confidence': round(topic_result['confidence'], 4),
            'model': topic_result.get('model', 'ruBERT'),
            'all_topics': topic_result.get('all_topics', [])
        },
        'processing_time': round(process_time, 3),
        'models': f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: BERT, –¢–µ–º–∞—Ç–∏–∫–∞: {topic_result.get('model', 'BERT')}"
    }
    
    return jsonify(response)

@app.route('/upload_excel', methods=['POST'])
def upload_excel():
    """–ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–∞"""
    print("=" * 50)
    print("üîÑ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞")
    print("=" * 50)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if 'file' not in request.files:
            print("‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ request.files")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 400
        
        file = request.files['file']
        print(f"üìÑ –ò–º—è —Ñ–∞–π–ª–∞: {file.filename}")
        
        if file.filename == '':
            print("‚ùå –û—à–∏–±–∫–∞: –ò–º—è —Ñ–∞–π–ª–∞ –ø—É—Å—Ç–æ–µ")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if not excel_processor.allowed_file(file.filename):
            print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç {file.filename}")
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .xlsx, .xls –∏–ª–∏ .csv'}), 400
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4()}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤: {filepath}")
        file.save(filepath)
        print("‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(filepath)
        print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–æ–Ω–∫–∞—Ö
        print("üîÑ –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª...")
        try:
            if filename.endswith('.csv'):
                print("üìÑ –û–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ CSV")
                df = pd.read_csv(filepath, encoding='utf-8')
            else:
                print("üìÑ –û–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ Excel")
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –¥–≤–∏–∂–∫–∏
                try:
                    df = pd.read_excel(filepath, engine='openpyxl')
                except:
                    print("‚ö†Ô∏è openpyxl –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º xlrd")
                    df = pd.read_excel(filepath, engine='xlrd')
            
            print(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω. –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}, —Å—Ç—Ä–æ–∫: {len(df)}")
            print(f"üìã –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫: {df.columns.tolist()}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
            return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏–∏
        session['current_file'] = filepath
        session['original_filename'] = filename
        print("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Å–µ—Å—Å–∏–∏")
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å –±—É–∫–≤–∞–º–∏
        columns_with_letters = []
        for i, col in enumerate(df.columns.tolist()):
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –≤ –±—É–∫–≤—É Excel (0->A, 1->B, 2->C, etc.)
            try:
                letter = excel_processor.get_column_letter(i)
            except:
                # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±
                letter = chr(65 + i) if i < 26 else f"Z{i-25}"  # A, B, C... Z, AA, AB...
            
            columns_with_letters.append({
                'index': i,
                'letter': letter,
                'name': str(col),
                'display': f"–ö–æ–ª–æ–Ω–∫–∞ {letter} - {col}"
            })
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
        preview_rows = []
        for i in range(min(5, len(df))):
            row = []
            for val in df.iloc[i].values:
                # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                str_val = str(val) if pd.notna(val) else ""
                if len(str_val) > 50:
                    str_val = str_val[:50] + "..."
                row.append(str_val)
            preview_rows.append(row)
        
        print("‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É")
        return jsonify({
            'success': True,
            'columns': columns_with_letters,
            'preview': {
                'columns': df.columns.tolist(),
                'rows': preview_rows
            }
        })
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/start_batch_analysis', methods=['POST'])
def start_batch_analysis():
    """–ó–∞–ø—É—Å–∫ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    data = request.get_json()
    
    # –ú–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å, —Ç–∞–∫ –∏ –±—É–∫–≤–∞ –∫–æ–ª–æ–Ω–∫–∏
    column_value = data.get('column', 0)
    options = data.get('options', {})
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±—É–∫–≤—É –≤ –∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if isinstance(column_value, str) and column_value.isalpha():
        column_index = excel_processor.letter_to_index(column_value.upper())
    else:
        column_index = int(column_value)
    
    filepath = session.get('current_file')
    original_filename = session.get('original_filename')
    
    if not filepath or not os.path.exists(filepath):
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 400
    
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        df, texts, column_name = excel_processor.read_excel(
            filepath, 
            column_index=column_index
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –±—É–∫–≤—É –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        column_letter = excel_processor.get_column_letter(column_index)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞–Ω–∏–µ
        job_id = batch_analyzer.create_job(
            filepath, 
            original_filename,
            {
                'column_name': column_name, 
                'column_index': column_index,
                'column_letter': column_letter,
                'options': options
            }
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ–Ω–µ
        import threading
        thread = threading.Thread(
            target=process_batch_job,
            args=(job_id, df, texts, column_name, options)
        )
        thread.daemon = True
        thread.start()
        
        return jsonify({'job_id': job_id})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def process_batch_job(job_id, df, texts, column_name, options):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –≤ —Ñ–æ–Ω–µ"""
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        batch_analyzer.update_job_progress(job_id, 0, len(texts))
        
        # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        def progress_callback(current, total):
            batch_analyzer.update_job_progress(job_id, current, total)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã
        results = excel_processor.analyze_batch(texts, progress_callback)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π DataFrame
        result_df = excel_processor.create_result_dataframe(df, column_name, results, options)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        output_path, output_filename = excel_processor.save_to_excel(
            result_df, 
            batch_analyzer.get_job(job_id)['original_filename'],
            app.config['DOWNLOAD_FOLDER']
        )
        
        # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞–Ω–∏–µ
        batch_analyzer.complete_job(job_id, output_path, output_filename)
        
    except Exception as e:
        batch_analyzer.fail_job(job_id, str(e))
        print(f"–û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞–Ω–∏–∏ {job_id}: {e}")

@app.route('/job_status/<job_id>')
def job_status(job_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞–Ω–∏—è"""
    job = batch_analyzer.get_job(job_id)
    
    if not job:
        return jsonify({'error': '–ó–∞–¥–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}), 404
    
    return jsonify({
        'status': job['status'],
        'progress': job['progress'],
        'total': job['total'],
        'error': job.get('error'),
        'result_filename': job.get('result_filename')
    })

@app.route('/download/<filename>')
def download_file(filename):
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    filepath = os.path.join(app.config['DOWNLOAD_FOLDER'], filename)
    
    if not os.path.exists(filepath):
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
    
    return send_file(
        filepath,
        as_attachment=True,
        download_name=filename,
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

@app.route('/test_topics')
def test_topics():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º"""
    test_texts = [
        "–°–µ–≥–æ–¥–Ω—è –ø—Ä–æ—à–µ–ª —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Ç—á —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ –º–∏—Ä–∞ –ø–æ —Ñ—É—Ç–±–æ–ª—É. –°–±–æ—Ä–Ω–∞—è –ë—Ä–∞–∑–∏–ª–∏–∏ –æ–¥–µ—Ä–∂–∞–ª–∞ –ø–æ–±–µ–¥—É —Å–æ —Å—á–µ—Ç–æ–º 2:1.",
        "Apple –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–π iPhone 15 —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–∞–º–µ—Ä–æ–π –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º A17.",
        "–í –ì–æ—Å–¥—É–º–µ –ø—Ä–∏–Ω—è–ª–∏ –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω –æ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö.",
        "–í—ã—à–µ–ª –Ω–æ–≤—ã–π —Ñ–∏–ª—å–º –ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä–∞ –ù–æ–ª–∞–Ω–∞. –í –≥–ª–∞–≤–Ω—ã—Ö —Ä–æ–ª—è—Ö —Å–Ω—è–ª–∏—Å—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∞–∫—Ç–µ—Ä—ã.",
        "–¶–µ–Ω—ã –Ω–∞ –Ω–µ—Ñ—Ç—å –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ —Ñ–æ–Ω–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –°–∞—É–¥–æ–≤—Å–∫–æ–π –ê—Ä–∞–≤–∏–∏.",
        "–£—á–µ–Ω—ã–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –Ω–æ–≤—É—é —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç—É –≤ –∑–æ–Ω–µ –æ–±–∏—Ç–∞–µ–º–æ—Å—Ç–∏.",
        "–í—Ä–∞—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –ø–∏—Ç—å –±–æ–ª—å—à–µ –≤–æ–¥—ã –∏ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è —Å–ø–æ—Ä—Ç–æ–º.",
        "–í –≠—Ä–º–∏—Ç–∞–∂–µ –æ—Ç–∫—Ä—ã–ª–∞—Å—å –≤—ã—Å—Ç–∞–≤–∫–∞ –∫–∞—Ä—Ç–∏–Ω –∏–º–ø—Ä–µ—Å—Å–∏–æ–Ω–∏—Å—Ç–æ–≤.",
        "–í —Ü–µ–Ω—Ç—Ä–µ –ú–æ—Å–∫–≤—ã –ø—Ä–æ–∏–∑–æ—à–ª–æ —Å–µ—Ä—å–µ–∑–Ω–æ–µ –î–¢–ü —Å —É—á–∞—Å—Ç–∏–µ–º —Ç—Ä–µ—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.",
        "–õ—É—á—à–∏–µ –æ—Ç–µ–ª–∏ –¢—É—Ä—Ü–∏–∏ –¥–ª—è —Å–µ–º–µ–π–Ω–æ–≥–æ –æ—Ç–¥—ã—Ö–∞ –Ω–∞ –º–æ—Ä–µ."
    ]
    
    results = []
    for text in test_texts:
        topic = topic_classifier.classify(text)
        results.append({
            'text': text[:50] + "...",
            'topic': topic['topic_name'],
            'confidence': topic['confidence'],
            'model': topic.get('model', '')
        })
    
    return jsonify(results)

@app.route('/model_info')
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –º–æ–¥–µ–ª—è—Ö"""
    model_type = type(topic_classifier).__name__
    
    info = {
        'sentiment_model': {
            'name': 'ruBERT –¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏',
            'model': 'blanchefort/rubert-base-cased-sentiment',
            'description': 'BERT –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤',
            'classes': ['positive', 'negative', 'neutral']
        },
        'topic_model': {
            'name': model_type,
            'description': '–ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–º–∞—Ç–∏–∫–∏',
            'topics': topic_classifier.get_all_topics()
        }
    }
    
    if model_type == 'BertTopicClassifier':
        info['topic_model']['model'] = 'Den4ikAI/ruBert-base-finetuned-russian-topic-classification'
    
    return jsonify(info)

@app.route('/demo_examples')
def demo_examples():
    """–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    examples = [
        {
            'text': '–≠—Ç–æ—Ç —Ñ–∏–ª—å–º –ø—Ä–æ—Å—Ç–æ –≤–µ–ª–∏–∫–æ–ª–µ–ø–µ–Ω! –ê–∫—Ç–µ—Ä—Å–∫–∞—è –∏–≥—Ä–∞ –Ω–∞ –≤—ã—Å–æ—Ç–µ, —Å—é–∂–µ—Ç –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Å –ø–µ—Ä–≤—ã—Ö –º–∏–Ω—É—Ç.',
            'expected_sentiment': 'positive',
            'expected_topic': 'entertainment'
        },
        {
            'text': '–£–∂–∞—Å–Ω—ã–π –º–∞—Ç—á, –Ω–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å. –ó–∞—â–∏—Ç–∞ –Ω–∏–∫–∞–∫–∞—è, –≤—Ä–∞—Ç–∞—Ä—å –ø—Ä–æ–ø—É—Å—Ç–∏–ª —Ç—Ä–∏ –≥–ª—É–ø—ã—Ö –≥–æ–ª–∞.',
            'expected_sentiment': 'negative',
            'expected_topic': 'sports'
        },
        {
            'text': '–í –ì–æ—Å–¥—É–º–µ –æ–±—Å—É–∂–¥–∞—é—Ç –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç –æ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö. –î–µ–ø—É—Ç–∞—Ç—ã –ø–ª–∞–Ω–∏—Ä—É—é—Ç –ø—Ä–∏–Ω—è—Ç—å –µ–≥–æ –¥–æ –∫–æ–Ω—Ü–∞ –º–µ—Å—è—Ü–∞.',
            'expected_sentiment': 'neutral',
            'expected_topic': 'politics'
        },
        {
            'text': 'Apple –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–π iPhone —Å –ø–æ—Ç—Ä—è—Å–∞—é—â–µ–π –∫–∞–º–µ—Ä–æ–π –∏ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é.',
            'expected_sentiment': 'positive',
            'expected_topic': 'technology'
        },
        {
            'text': '–£—á–µ–Ω—ã–µ –∏–∑ –ú–ì–£ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ª–µ—á–µ–Ω–∏—è —Ä–∞–∫–∞ —Å –ø–æ–º–æ—â—å—é –Ω–∞–Ω–æ—á–∞—Å—Ç–∏—Ü.',
            'expected_sentiment': 'positive',
            'expected_topic': 'science'
        }
    ]
    return jsonify({'examples': examples})

@app.route('/batch_status')
def batch_status():
    """–°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∑–∞–¥–∞–Ω–∏–π"""
    batch_analyzer.cleanup_old_jobs()
    
    return jsonify({
        'active_jobs': len(batch_analyzer.jobs),
        'jobs': [
            {
                'id': j['id'],
                'status': j['status'],
                'progress': f"{j['progress']}/{j['total']}",
                'filename': j['original_filename']
            }
            for j in batch_analyzer.jobs.values()
        ]
    })

if __name__ == '__main__':
    print("=" * 60)
    print("üöÄ –ó–ê–ü–£–°–ö BERT-–ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê –° –ü–ê–ö–ï–¢–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–û–ô")
    print("=" * 60)
    print("üìä –ú–æ–¥–µ–ª–∏:")
    print("  - –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ruBERT (blanchefort/rubert-base-cased-sentiment)")
    print(f"  - –¢–µ–º–∞—Ç–∏–∫–∞: {type(topic_classifier).__name__}")
    print("=" * 60)
    print("üåê –û–¥–∏–Ω–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑: http://localhost:5000")
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ Excel: http://localhost:5000/upload")
    print("üìù –¢–µ—Å—Ç —Ç–µ–º: http://localhost:5000/test_topics")
    print("=" * 60)
    
    # –û—á–∏—â–∞–µ–º –∫—ç—à GPU –µ—Å–ª–∏ –µ—Å—Ç—å
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    app.run(debug=True, port=5000, threaded=True)