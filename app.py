from flask import Flask, render_template, request, jsonify, send_file, session
from sentiment_model import BertSentimentAnalyzer
from topic_model import BertTopicClassifier, SimpleTopicClassifier
from excel_processor import ExcelProcessor, BatchAnalyzer
import time
import torch
import os
import uuid
import pandas as pd
import threading
from werkzeug.utils import secure_filename

app = Flask(__name__)
app.secret_key = 'your-secret-key-here-2024'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['DOWNLOAD_FOLDER'] = 'downloads'

os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['DOWNLOAD_FOLDER'], exist_ok=True)

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ñ–ª–∞–≥–æ–≤ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
stop_flags = {}

print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ BERT –º–æ–¥–µ–ª–µ–π...")

sentiment_analyzer = BertSentimentAnalyzer()

try:
    topic_classifier = BertTopicClassifier()
    test_result = topic_classifier.classify("—Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
    if test_result['topic'] == 'other' and test_result['confidence'] < 0.6:
        print("‚ö†Ô∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –ø—Ä–æ—Å—Ç—É—é...")
        topic_classifier = SimpleTopicClassifier()
    else:
        print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è BERT –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–º–∞—Ç–∏–∫–∏")
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ BERT –º–æ–¥–µ–ª–∏: {e}")
    print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞—Ö")
    topic_classifier = SimpleTopicClassifier()

excel_processor = ExcelProcessor(sentiment_analyzer, topic_classifier)
batch_analyzer = BatchAnalyzer(excel_processor)

print("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

@app.route('/')
def index():
    topics = topic_classifier.get_all_topics()
    return render_template('index.html', topics=topics, model_type=type(topic_classifier).__name__)

@app.route('/upload')
def upload_page():
    return render_template('upload.html')

@app.route('/analyze', methods=['POST'])
def analyze_text():
    data = request.get_json()
    
    if not data or 'text' not in data:
        return jsonify({'error': '–ù–µ —É–∫–∞–∑–∞–Ω —Ç–µ–∫—Å—Ç'}), 400
    
    text = data['text'].strip()
    
    if not text:
        return jsonify({'error': '–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç'}), 400
    
    start_time = time.time()
    
    sentiment_result = sentiment_analyzer.analyze(text)
    topic_result = topic_classifier.classify(text)
    
    process_time = time.time() - start_time
    
    emoji_map = {
        'positive': 'üòä',
        'negative': 'üò†', 
        'neutral': 'üòê'
    }
    
    response = {
        'text': text,
        'sentiment': {
            'label': sentiment_result['sentiment'],
            'confidence': round(sentiment_result['confidence'], 4),
            'emoji': emoji_map.get(sentiment_result['sentiment'], 'ü§î'),
            'model': 'ruBERT (—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)',
            'probabilities': sentiment_result.get('probabilities', {})
        },
        'topic': {
            'label': topic_result['topic'],
            'name': topic_result['topic_name'],
            'confidence': round(topic_result['confidence'], 4),
            'model': topic_result.get('model', 'ruBERT'),
            'all_topics': topic_result.get('all_topics', [])
        },
        'processing_time': round(process_time, 3),
        'models': f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: BERT, –¢–µ–º–∞—Ç–∏–∫–∞: {topic_result.get('model', 'BERT')}"
    }
    
    return jsonify(response)

@app.route('/upload_excel', methods=['POST'])
def upload_excel():
    print("=" * 50)
    print("üîÑ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞")
    print("=" * 50)
    
    try:
        if 'file' not in request.files:
            print("‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ request.files")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 400
        
        file = request.files['file']
        print(f"üìÑ –ò–º—è —Ñ–∞–π–ª–∞: {file.filename}")
        
        if file.filename == '':
            print("‚ùå –û—à–∏–±–∫–∞: –ò–º—è —Ñ–∞–π–ª–∞ –ø—É—Å—Ç–æ–µ")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
        
        if not excel_processor.allowed_file(file.filename):
            print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç {file.filename}")
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .xlsx, .xls –∏–ª–∏ .csv'}), 400
        
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4()}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤: {filepath}")
        file.save(filepath)
        print("‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
        file_size = os.path.getsize(filepath)
        print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
        
        print("üîÑ –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª...")
        try:
            if filename.endswith('.csv'):
                print("üìÑ –û–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ CSV")
                df = pd.read_csv(filepath, encoding='utf-8')
            else:
                print("üìÑ –û–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ Excel")
                try:
                    df = pd.read_excel(filepath, engine='openpyxl')
                except:
                    print("‚ö†Ô∏è openpyxl –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º xlrd")
                    df = pd.read_excel(filepath, engine='xlrd')
            
            print(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω. –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}, —Å—Ç—Ä–æ–∫: {len(df)}")
            print(f"üìã –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫: {df.columns.tolist()}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
            return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
        
        session['current_file'] = filepath
        session['original_filename'] = filename
        print("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Å–µ—Å—Å–∏–∏")
        
        columns_with_letters = []
        for i, col in enumerate(df.columns.tolist()):
            try:
                letter = excel_processor.get_column_letter(i)
            except:
                if i < 26:
                    letter = chr(65 + i)
                else:
                    first = chr(65 + (i // 26) - 1)
                    second = chr(65 + (i % 26))
                    letter = first + second
            
            columns_with_letters.append({
                'index': i,
                'letter': letter,
                'name': str(col),
                'display': f"–ö–æ–ª–æ–Ω–∫–∞ {letter} - {col}"
            })
        
        preview_rows = []
        for i in range(min(5, len(df))):
            row = []
            for val in df.iloc[i].values:
                str_val = str(val) if pd.notna(val) else ""
                if len(str_val) > 50:
                    str_val = str_val[:50] + "..."
                row.append(str_val)
            preview_rows.append(row)
        
        print("‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É")
        return jsonify({
            'success': True,
            'columns': columns_with_letters,
            'total_rows': len(df),
            'preview': {
                'columns': df.columns.tolist(),
                'rows': preview_rows
            }
        })
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/start_batch_analysis', methods=['POST'])
def start_batch_analysis():
    data = request.get_json()
    
    column_value = data.get('column', 0)
    row_limit = data.get('row_limit', 0)
    
    if isinstance(column_value, str) and column_value.isalpha():
        column_index = excel_processor.letter_to_index(column_value.upper())
    else:
        column_index = int(column_value)
    
    filepath = session.get('current_file')
    original_filename = session.get('original_filename')
    
    if not filepath or not os.path.exists(filepath):
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 400
    
    try:
        df, texts, column_name = excel_processor.read_excel(
            filepath, 
            column_index=column_index
        )
        
        total_rows = len(texts)
        if row_limit > 0 and row_limit < total_rows:
            texts = texts[:row_limit]
            print(f"üìä –ê–Ω–∞–ª–∏–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω: {row_limit} –∏–∑ {total_rows} —Å—Ç—Ä–æ–∫")
        else:
            print(f"üìä –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö {total_rows} —Å—Ç—Ä–æ–∫")
        
        column_letter = excel_processor.get_column_letter(column_index)
        
        job_id = batch_analyzer.create_job(
            filepath, 
            original_filename,
            {
                'column_name': column_name, 
                'column_index': column_index,
                'column_letter': column_letter,
                'row_limit': row_limit,
                'total_rows': total_rows
            }
        )
        
        thread = threading.Thread(
            target=process_batch_job,
            args=(job_id, df, texts, column_name)
        )
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'job_id': job_id,
            'rows_to_process': len(texts),
            'total_rows': total_rows
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def process_batch_job(job_id, df, texts, column_name):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –≤ —Ñ–æ–Ω–µ"""
    try:
        batch_analyzer.update_job_progress(job_id, 0, len(texts))
        
        def progress_callback(current, total):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—Ä–æ—à–µ–Ω–∞ –ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
            if stop_flags.get(job_id, False):
                print(f"üõë –ó–∞–¥–∞–Ω–∏–µ {job_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É")
                raise Exception("Analysis stopped by user")
            batch_analyzer.update_job_progress(job_id, current, total)
        
        results = excel_processor.analyze_batch(texts, progress_callback)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º DataFrame
        if stop_flags.get(job_id, False):
            print(f"üõë –ó–∞–¥–∞–Ω–∏–µ {job_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
            return
        
        result_df = excel_processor.create_result_dataframe(df, column_name, results)
        
        output_path, output_filename = excel_processor.save_to_excel(
            result_df, 
            batch_analyzer.get_job(job_id)['original_filename'],
            app.config['DOWNLOAD_FOLDER']
        )
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        if stop_flags.get(job_id, False):
            print(f"üõë –ó–∞–¥–∞–Ω–∏–µ {job_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ, —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
            if os.path.exists(output_path):
                os.remove(output_path)
            return
        
        batch_analyzer.complete_job(job_id, output_path, output_filename)
        print(f"‚úÖ –ó–∞–¥–∞–Ω–∏–µ {job_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –§–∞–π–ª: {output_filename}")
        
    except Exception as e:
        if str(e) == "Analysis stopped by user":
            print(f"üõë –ó–∞–¥–∞–Ω–∏–µ {job_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            batch_analyzer.fail_job(job_id, "–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        else:
            batch_analyzer.fail_job(job_id, str(e))
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞–Ω–∏–∏ {job_id}: {e}")
            import traceback
            traceback.print_exc()
    finally:
        # –û—á–∏—â–∞–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        if job_id in stop_flags:
            del stop_flags[job_id]

@app.route('/stop_analysis/<job_id>', methods=['POST'])
def stop_analysis(job_id):
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    job = batch_analyzer.get_job(job_id)
    
    if not job:
        return jsonify({'error': '–ó–∞–¥–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}), 404
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    stop_flags[job_id] = True
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞–Ω–∏—è
    job['status'] = 'cancelled'
    job['error'] = '–ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º'
    
    print(f"üõë –ê–Ω–∞–ª–∏–∑ {job_id} –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    
    return jsonify({'success': True, 'message': '–ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'})

@app.route('/job_status/<job_id>')
def job_status(job_id):
    job = batch_analyzer.get_job(job_id)
    
    if not job:
        return jsonify({'error': '–ó–∞–¥–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}), 404
    
    return jsonify({
        'status': job['status'],
        'progress': job['progress'],
        'total': job['total'],
        'error': job.get('error'),
        'result_filename': job.get('result_filename')
    })

@app.route('/download/<filename>')
def download_file(filename):
    filepath = os.path.join(app.config['DOWNLOAD_FOLDER'], filename)
    
    if not os.path.exists(filepath):
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
    
    return send_file(
        filepath,
        as_attachment=True,
        download_name=filename,
        mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

@app.route('/test_topics')
def test_topics():
    test_texts = [
        "–°–µ–≥–æ–¥–Ω—è –ø—Ä–æ—à–µ–ª —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Ç—á —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ –º–∏—Ä–∞ –ø–æ —Ñ—É—Ç–±–æ–ª—É.",
        "Apple –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–π iPhone 15 —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–∞–º–µ—Ä–æ–π.",
        "–í –ì–æ—Å–¥—É–º–µ –ø—Ä–∏–Ω—è–ª–∏ –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω –æ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö.",
        "–í—ã—à–µ–ª –Ω–æ–≤—ã–π —Ñ–∏–ª—å–º –ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä–∞ –ù–æ–ª–∞–Ω–∞.",
        "–¶–µ–Ω—ã –Ω–∞ –Ω–µ—Ñ—Ç—å –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ —Ñ–æ–Ω–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –°–∞—É–¥–æ–≤—Å–∫–æ–π –ê—Ä–∞–≤–∏–∏."
    ]
    
    results = []
    for text in test_texts:
        topic = topic_classifier.classify(text)
        results.append({
            'text': text[:50] + "...",
            'topic': topic['topic_name'],
            'confidence': topic['confidence'],
            'model': topic.get('model', '')
        })
    
    return jsonify(results)

@app.route('/model_info')
def model_info():
    model_type = type(topic_classifier).__name__
    
    info = {
        'sentiment_model': {
            'name': 'ruBERT –¥–ª—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏',
            'model': 'blanchefort/rubert-base-cased-sentiment',
            'description': 'BERT –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤',
            'classes': ['positive', 'negative', 'neutral']
        },
        'topic_model': {
            'name': model_type,
            'description': '–ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–º–∞—Ç–∏–∫–∏',
            'topics': topic_classifier.get_all_topics()
        }
    }
    
    return jsonify(info)

@app.route('/demo_examples')
def demo_examples():
    examples = [
        {'text': '–≠—Ç–æ—Ç —Ñ–∏–ª—å–º –ø—Ä–æ—Å—Ç–æ –≤–µ–ª–∏–∫–æ–ª–µ–ø–µ–Ω!', 'expected_sentiment': 'positive', 'expected_topic': 'entertainment'},
        {'text': '–£–∂–∞—Å–Ω—ã–π –º–∞—Ç—á, –Ω–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å.', 'expected_sentiment': 'negative', 'expected_topic': 'sports'},
        {'text': '–í –ì–æ—Å–¥—É–º–µ –æ–±—Å—É–∂–¥–∞—é—Ç –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç.', 'expected_sentiment': 'neutral', 'expected_topic': 'politics'}
    ]
    return jsonify({'examples': examples})

@app.route('/batch_status')
def batch_status():
    batch_analyzer.cleanup_old_jobs()
    
    return jsonify({
        'active_jobs': len(batch_analyzer.jobs),
        'jobs': [
            {
                'id': j['id'],
                'status': j['status'],
                'progress': f"{j['progress']}/{j['total']}",
                'filename': j['original_filename']
            }
            for j in batch_analyzer.jobs.values()
        ]
    })

if __name__ == '__main__':
    print("=" * 60)
    print("üöÄ –ó–ê–ü–£–°–ö BERT-–ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê")
    print("=" * 60)
    print("üåê –û–¥–∏–Ω–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑: http://localhost:5000")
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ Excel: http://localhost:5000/upload")
    print("=" * 60)
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    app.run(debug=True, port=5000, threaded=True)